{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import string\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "from datetime import date\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_unprocessed = pd.read_csv('../Datasets/combined_dataset_all.csv', \n",
    "                                                 encoding = \"ISO-8859-1\", dtype={\"split\": \"string\", \"message\": \"string\", \"genre\": \"string\"})\n",
    "val_yes_disater_unprocessed = pd.read_csv('../Datasets/ValidationUseCaseDisaster.csv', \n",
    "                                          encoding = \"ISO-8859-1\", dtype={\"message\": \"string\", \"date\": \"string\",\"location\": \"string\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting any 0 to 2 (translates to no)\n",
    "dataset= dataset_unprocessed.replace(2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting any 'off-topic' to '0' and 'on-topic' to 1 in disaster_yes val set\n",
    "val_yes_disater = val_yes_disater_unprocessed.replace(to_replace=['off-topic', 'on-topic'], value=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_yes_disater = val_yes_disater_unprocessed.drop(columns = ['related'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>related</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've got enough candles to supply a Mexican fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sandy be soooo mad that she be shattering our ...</td>\n",
       "      <td>1</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ibexgirl thankfully Hurricane Waugh played it...</td>\n",
       "      <td>0</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@taos you never got that magnificent case of B...</td>\n",
       "      <td>0</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm at Mad River Bar &amp;amp; Grille (New York, N...</td>\n",
       "      <td>0</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Neighborly duties. @Cory_Kennedy arrives to th...</td>\n",
       "      <td>1</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>And that's it until the spring.</td>\n",
       "      <td>0</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I don't know how I'm getting back to Jersey si...</td>\n",
       "      <td>1</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@NaeemPeena We were asked to get off the plane...</td>\n",
       "      <td>0</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@jaytee_96 you must be crazy! &amp;amp; omg you tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Already flooded so much #SANDY @ Hoboken http:...</td>\n",
       "      <td>1</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@eloreeeeeee need me to comeback and finish it...</td>\n",
       "      <td>0</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>On that note, i pray that everyone stays safe,...</td>\n",
       "      <td>1</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@codyfinz my house is creeking... Does that me...</td>\n",
       "      <td>1</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>My mom just found my little sister screaming o...</td>\n",
       "      <td>0</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RT @FrankIero: Droplets of water is literally ...</td>\n",
       "      <td>0</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@NevaTRUST_Again I Dnt No If She Gonna Let Me</td>\n",
       "      <td>0</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@jennettemccurdy @noahmunck He's got that kind...</td>\n",
       "      <td>0</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>debating going home in prep for #sandy</td>\n",
       "      <td>1</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@viamadison Thanks, babe. We all appreciate it...</td>\n",
       "      <td>0</td>\n",
       "      <td>28/10/2012</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              message  related        date  \\\n",
       "0   I've got enough candles to supply a Mexican fa...        0  28/10/2012   \n",
       "1   Sandy be soooo mad that she be shattering our ...        1  28/10/2012   \n",
       "2   @ibexgirl thankfully Hurricane Waugh played it...        0  28/10/2012   \n",
       "3   @taos you never got that magnificent case of B...        0  28/10/2012   \n",
       "4   I'm at Mad River Bar &amp; Grille (New York, N...        0  28/10/2012   \n",
       "5   Neighborly duties. @Cory_Kennedy arrives to th...        1  28/10/2012   \n",
       "6                     And that's it until the spring.        0  28/10/2012   \n",
       "7   I don't know how I'm getting back to Jersey si...        1  28/10/2012   \n",
       "8   @NaeemPeena We were asked to get off the plane...        0  28/10/2012   \n",
       "9   @jaytee_96 you must be crazy! &amp; omg you tw...        0  28/10/2012   \n",
       "10  Already flooded so much #SANDY @ Hoboken http:...        1  28/10/2012   \n",
       "11  @eloreeeeeee need me to comeback and finish it...        0  28/10/2012   \n",
       "12  On that note, i pray that everyone stays safe,...        1  28/10/2012   \n",
       "13  @codyfinz my house is creeking... Does that me...        1  28/10/2012   \n",
       "14  My mom just found my little sister screaming o...        0  28/10/2012   \n",
       "15  RT @FrankIero: Droplets of water is literally ...        0  28/10/2012   \n",
       "16      @NevaTRUST_Again I Dnt No If She Gonna Let Me        0  28/10/2012   \n",
       "17  @jennettemccurdy @noahmunck He's got that kind...        0  28/10/2012   \n",
       "18             debating going home in prep for #sandy        1  28/10/2012   \n",
       "19  @viamadison Thanks, babe. We all appreciate it...        0  28/10/2012   \n",
       "\n",
       "                   location  \n",
       "0   New York City, New York  \n",
       "1   New York City, New York  \n",
       "2   New York City, New York  \n",
       "3   New York City, New York  \n",
       "4   New York City, New York  \n",
       "5   New York City, New York  \n",
       "6   New York City, New York  \n",
       "7   New York City, New York  \n",
       "8   New York City, New York  \n",
       "9   New York City, New York  \n",
       "10  New York City, New York  \n",
       "11  New York City, New York  \n",
       "12  New York City, New York  \n",
       "13  New York City, New York  \n",
       "14  New York City, New York  \n",
       "15  New York City, New York  \n",
       "16  New York City, New York  \n",
       "17  New York City, New York  \n",
       "18  New York City, New York  \n",
       "19  New York City, New York  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_yes_disater.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10008, 4)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_yes_disater.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimising the dataset further ready for model training\n",
    "dataset.drop(dataset.columns.difference(['message', 'related']), 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>Thank you for the answer, because I think we a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12371</th>\n",
       "      <td>The Swedish Committee for Afghanistan (SCA) wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18614</th>\n",
       "      <td>Omg, whats with Windows Vista today. Tried ins...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37543</th>\n",
       "      <td>In some areas, floodwaters reached as high as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7756</th>\n",
       "      <td>These early rains were not nearly enough to ea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  related\n",
       "1311   Thank you for the answer, because I think we a...        1\n",
       "12371  The Swedish Committee for Afghanistan (SCA) wi...        1\n",
       "18614  Omg, whats with Windows Vista today. Tried ins...        0\n",
       "37543  In some areas, floodwaters reached as high as ...        1\n",
       "7756   These early rains were not nearly enough to ea...        1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Weather update - a cold front from Cuba that could pass over Haiti'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# having apeek at the first message\n",
    "dataset['message'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean the data\n",
    "def clean_text(text):\n",
    "    # make all text lowercase\n",
    "    text = text.lower()\n",
    "    # substitute common abbreviations\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    # removes any leading spaces at the beginning and trailing spaces at the end\n",
    "    text = text.strip(' ')\n",
    "    # new bit\n",
    "    # remove punctuations\n",
    "    words = text.split()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in words]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    # stemming of words\n",
    "    porter = PorterStemmer()\n",
    "    stemmed = [porter.stem(word) for word in words]\n",
    "    seperator = \" \"\n",
    "    text = seperator.join(words)\n",
    "#     print(words)\n",
    "#     print(\"---\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['message'] = dataset['message'].map(lambda com : clean_text(com))\n",
    "#dataset['message'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_yes_disater['message'] = val_yes_disater['message'].map(lambda com : clean_text(com))\n",
    "#val_yes_disater['message'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34436,)\n",
      "(34436,)\n"
     ]
    }
   ],
   "source": [
    "categories = ['related']\n",
    "train, test = train_test_split(dataset, random_state=42, test_size=0.10, shuffle=True)\n",
    "X_train = train.message\n",
    "X_validate_yes = val_yes_disater.message\n",
    "y_train = train.related\n",
    "# y_validate_yes = val_yes_disater.related\n",
    "predictionsArray = np.array([])\n",
    "targetValuesArray = np.array([])\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding all the VALIDATION YES data to an array used for classification report\n",
    "# for column in val_yes_disater[['related']]:\n",
    "#     columnSeriesObj = val_yes_disater[column]\n",
    "#     targetValuesArray = np.append(targetValuesArray, columnSeriesObj.values)\n",
    "\n",
    "# print(targetValuesArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing related\n",
      "Done! Predictions Complete\n"
     ]
    }
   ],
   "source": [
    "# Define a pipeline combining a text feature extractor with multi label classifier\n",
    "NB_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', LogisticRegression()),\n",
    "            ])\n",
    "# print accuracy for each label\n",
    "for category in categories:\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    NB_pipeline.fit(X_train, train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction = NB_pipeline.predict(X_validate_yes) ### pass in X_validate_yes, X_validate_no OR X_test\n",
    "    predictionsArray = np.append(predictionsArray, prediction)\n",
    "    print(\"Done! Predictions Complete\")\n",
    "#     print('Test accuracy is {}'.format('%.2f' % accuracy_score(val_yes_disater[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions\n",
      "(10008,)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# view predictions and true values arrays\n",
    "print(\"Predictions\")\n",
    "print(np.shape(predictionsArray))\n",
    "print(\" \")\n",
    "# for x in predictionsArray:\n",
    "#     print(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A disaster is currently happening! \n",
      "6581\n"
     ]
    }
   ],
   "source": [
    "# first check if there are enough positive predictions to suggest a disaster is occuring\n",
    "disasterRelatedTweets = 0\n",
    "for prediction in predictionsArray:\n",
    "    if (prediction == 1):\n",
    "        disasterRelatedTweets += 1;\n",
    "if(disasterRelatedTweets >=3000):\n",
    "    print (\"A disaster is currently happening! \")\n",
    "    print (disasterRelatedTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  IF No, return \"no disasters\"\n",
    "#  IF Yes : see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append predictions to validation dataframe\n",
    "val_yes_disater['model_prediction'] = np.array(predictionsArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10008, 5)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_yes_disater.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where prediction = 0 (they aren't disaster related)\n",
    "val_yes_disater_reduced = val_yes_disater.query(\"model_prediction > 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6581, 5)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_yes_disater_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 2 seperate arrays: one with the locations to pass and the other with the amount of tweets per city\n",
    "ResultsLocationArray = np.array([])\n",
    "ResultsLocationRatiosArray = np.array([])\n",
    "ResultsArray = np.array([])\n",
    "ResultsLocationArray = np.append(val_yes_disater_reduced.location.unique(), ResultsLocationArray)\n",
    "ResultsLocationRatiosArray = np.append(val_yes_disater_reduced['location'].value_counts(), ResultsLocationRatiosArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York City, New York\n",
      "Bergen County, New Jersey\n",
      "Atlantic City, New Jersey\n",
      "Essex, Massachusetts\n",
      "Monmouth County, New Jersey\n",
      "Middlesex County, New York\n",
      "Cape May, New Jersey\n",
      "1936\n",
      "1332\n",
      "1316\n",
      "960\n",
      "350\n",
      "347\n",
      "340\n"
     ]
    }
   ],
   "source": [
    "for result in ResultsLocationArray:\n",
    "    print(result)\n",
    "for result in ResultsLocationRatiosArray:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  combine these 2 array into 1 2D array\n",
    "i = 0\n",
    "while i < ResultsLocationArray.size:\n",
    "    ResultsArray = np.append([ResultsLocationArray[i],ResultsLocationRatiosArray[i]], ResultsArray)\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cape May, New Jersey\n",
      "340\n",
      "Middlesex County, New York\n",
      "347\n",
      "Monmouth County, New Jersey\n",
      "350\n",
      "Essex, Massachusetts\n",
      "960\n",
      "Atlantic City, New Jersey\n",
      "1316\n",
      "Bergen County, New Jersey\n",
      "1332\n",
      "New York City, New York\n",
      "1936\n"
     ]
    }
   ],
   "source": [
    "# pass the 'ResultsArray' to Lambda 1 who'll pass it onto the web application\n",
    "for result in ResultsArray:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
